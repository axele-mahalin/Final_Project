{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import file about the french museums infos\n",
    "\n",
    "Paris_exhibitions=pd.read_csv('Data_sources/que-faire-a-paris.csv', sep=';', encoding='UTF8')\n",
    "Paris_exhibitions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "\n",
    "# def evaluate_model(note, model, X_test, y_test, results):\n",
    "#     pred = model.predict(X_test)\n",
    "#     score = model.score(X_test, y_test)\n",
    "#     precision = precision_score(y_test,pred)\n",
    "#     recall = recall_score(y_test, pred)\n",
    "#     f1 = f1_score(y_test, pred)\n",
    "#     false_negatives = confusion_matrix(y_test, pred)[1][0]\n",
    "#     new_result = pd.DataFrame({'note':note,'accuracy':score,'precision':precision,'recall':recall,'f1_score':f1,'false_negatives':false_negatives},index=[0])\n",
    "#     return pd.concat([results,new_result],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install git+https://github.com/ClaudeCoulombe/FrenchLefffLemmatizer.git &> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from nltk.stem.snowball import EnglishStemmer\n",
    "#from sklearn.feature_extraction._stop_words import ENGLISH_STOP_WORDS\n",
    "\n",
    "import nltk\n",
    "import string\n",
    "from french_lefff_lemmatizer.french_lefff_lemmatizer import FrenchLefffLemmatizer\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings = list(Paris_exhibitions[\"chapeau\"])\n",
    "strings_without_digits = []\n",
    "\n",
    "# Utilisation de regex pour enlever les chiffres\n",
    "pattern = r\"\\d+\"  # Le motif \\d+ correspond à un ou plusieurs chiffres\n",
    "\n",
    "for s in strings:\n",
    "    if isinstance(s, str):\n",
    "        s_without_digits = re.sub(pattern, \"\", s)\n",
    "        strings_without_digits.append(s_without_digits)\n",
    "    else:\n",
    "        strings_without_digits.append(s)\n",
    "\n",
    "# Affichage des résultats\n",
    "for s in strings_without_digits:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(strings_without_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "texts = [\"\" if pd.isna(text) else text for text in strings_without_digits]\n",
    "vectors = vectorizer.fit_transform(texts)\n",
    "vocabulary = vectorizer.get_feature_names_out()\n",
    "\n",
    "df = pd.DataFrame(vectors.toarray(), columns=vocabulary, index=texts)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "french_stopwords = nltk.corpus.stopwords.words('french')\n",
    "mots = strings_without_digits\n",
    "lemmatizer = FrenchLefffLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocess_listofSentence(strings_without_digits):\n",
    " preprocess_list = []\n",
    " for sentence in listofSentence :\n",
    "  sentence_w_punct = \"\".join([i.lower() for i in sentence if i not in string.punctuation])\n",
    "\n",
    "  sentence_w_num = ''.join(i for i in sentence_w_punct if not i.isdigit())\n",
    "\n",
    "  tokenize_sentence = nltk.tokenize.word_tokenize(sentence_w_num)\n",
    "\n",
    "  words_w_stopwords = [i for i in tokenize_sentence if i not in stopwords]\n",
    "\n",
    "  words_lemmatize = (lemmatizer.lemmatize(w) for w in words_w_stopwords)\n",
    "\n",
    "  sentence_clean = ' '.join(w for w in words_lemmatize if w.lower() in words or not w.isalpha())\n",
    "\n",
    "  preprocess_list.append(sentence_clean)\n",
    "\n",
    " return preprocess_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess_list = Preprocess_listofSentence(train_data['strings_without_digits'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paris_exhibitions = df\n",
    "\n",
    "# df = train_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
